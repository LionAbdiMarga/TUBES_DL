# -*- coding: utf-8 -*-
"""dl-tb.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dwyDkHy8ywLb5g77_hqp8u5n-EIuQ3-s
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import tensorflow as tf
from sklearn.metrics import confusion_matrix
import seaborn as sns
from keras.preprocessing import image
from tensorflow.keras.models import load_model

train_datagen = ImageDataGenerator(rescale = 1./255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = False)

test_datagen = ImageDataGenerator(rescale = 1./255)

"""## Melspec"""

training_set = train_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/melspec_split/train',
                                                 target_size = (64, 64),
                                                 shuffle=True)

test_set = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/melspec_split/val',
                                            target_size = (64, 64),
                                            shuffle=False)

#VGG
model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(64, (3, 3), input_shape=(64, 64, 3), padding='same', activation='relu'),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same',),
    tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dense(4096, activation='relu'),
    tf.keras.layers.Dense(6, activation='softmax')
])

model.summary()

from keras.callbacks import History
history = History()

optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)

model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
model.summary()

History = model.fit(training_set, validation_data = test_set, batch_size=64,epochs=15,callbacks=[history])

plt.figure(figsize=(14,8))
plt.plot(History.history['accuracy'])
plt.plot(History.history['val_accuracy'])
plt.title('Model Accuracy', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

 # summarize history for loss
plt.figure(figsize=(14,8))
plt.plot(History.history['loss'])
plt.plot(History.history['val_loss'])
plt.title('Model Loss', fontsize=14)
plt.ylabel('Loss',fontsize=12)
plt.xlabel('Epoch',fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

training_set_mfcc = train_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/train',
                                                 target_size = (64, 64),
                                                 shuffle=True)

test_set_mfcc = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/val',
                                            target_size = (64, 64),
                                            shuffle=False)

target_names = []
for key in training_set.class_indices:
  target_names.append(key)

print(target_names)

import sklearn
print(sklearn.__version__)

from sklearn.metrics import confusion_matrix
#from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
import seaborn as sns

accuracy = model.evaluate(test_set)
print('n', 'Test_Accuracy:-', accuracy[1])
pred = model.predict(test_set)
y_pred = np.argmax(pred, axis=1)
#y_true = np.argmax(pred, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set.classes, y_pred))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set.classes, y_pred), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred")
plt.ylabel("y_true")
plt.show()

print('Classification Report')
print(classification_report(test_set.classes, y_pred, target_names=target_names ))

accuracy = model.evaluate(test_set)
print('n', 'Test_Accuracy:-', accuracy[1])

"""Prediksi dengan data yang belum digunakan sama sekali"""

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set1 = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/melspec_split/test',
                                            target_size = (64, 64),
                                            shuffle=False)#berbeda dengan test_set diatas, diatas menggunakan validasi sedangkan ini menggunakan data dari folder test

accuracy = model.evaluate(test_set1)
print('n', 'Test_Accuracy:-', accuracy[1])
pred1 = model.predict(test_set1)
y_pred1 = np.argmax(pred1, axis=1)
#y_true = np.argmax(pred1, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set1.classes, y_pred1))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set1.classes, y_pred1), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred1")
plt.ylabel("y_true")
plt.show()

accuracy = model.evaluate(test_set1)
print('n', 'Test_Accuracy:-', accuracy[1])

"""## MFCC"""

History1 = model.fit(training_set_mfcc, validation_data = test_set_mfcc, batch_size=64,epochs=15,callbacks=[history])

plt.figure(figsize=(14,8))
plt.plot(History1.history['accuracy'])

plt.plot(History1.history['val_accuracy'])
plt.title('Model Accuracy', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

 # summarize history for loss
plt.figure(figsize=(14,8))
plt.plot(History1.history['loss'])
plt.plot(History1.history['val_loss'])
plt.title('Model Loss', fontsize=14)
plt.ylabel('Loss',fontsize=12)
plt.xlabel('Epoch',fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

accuracy = model.evaluate(test_set_mfcc)
print('n', 'Test_Accuracy:-', accuracy[1])
pred = model.predict(test_set_mfcc)
y_pred = np.argmax(pred, axis=1)
#y_true = np.argmax(pred, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set_mfcc.classes, y_pred))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set_mfcc.classes, y_pred), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred")
plt.ylabel("y_true")
plt.show()

accuracy = model.evaluate(test_set_mfcc)
print('n', 'Test_Accuracy:-', accuracy[1])

"""Prediksi dengan data yang belum digunakan (test) bukan validation"""

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set2 = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/test',
                                            target_size = (64, 64),
                                            shuffle=False)#menggunakan folder test dari mfcc

accuracy = model.evaluate(test_set2)
print('n', 'Test_Accuracy:-', accuracy[1])
pred2 = model.predict(test_set2)
y_pred2 = np.argmax(pred2, axis=1)
#y_true = np.argmax(pred2, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set2.classes, y_pred2))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set2.classes, y_pred2), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred2")
plt.ylabel("y_true")
plt.show()

"""# RESNET"""

import tensorflow as tf
from keras.callbacks import History

# Function to create a residual block with shortcut adjustment
def residual_block(x, filters, use_shortcut=True):
    shortcut = x
    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)
    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)

    if use_shortcut:
        # Adjust shortcut if the number of filters has changed
        if x.shape[-1] != shortcut.shape[-1]:
            shortcut = tf.keras.layers.Conv2D(filters, (1, 1), padding='same')(shortcut)

    x = tf.keras.layers.add([x, shortcut])  # Add shortcut connection
    x = tf.keras.layers.Activation('relu')(x)
    return x

# Build ResNet model_RESNETmelspec
def build_resnet(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(64, (7, 7), padding='same', activation='relu')(inputs)
    x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)

    # Add residual blocks
    for _ in range(2):  # Repeat 2 times for each block
        x = residual_block(x, 64)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 128)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 256)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 512)

    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(512, activation='relu')(x)
    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

    model_RESNETmelspec = tf.keras.Model(inputs, outputs)
    return model_RESNETmelspec

# Instantiate and compile the model_RESNETmelspec
model_RESNETmelspec = build_resnet(input_shape=(64, 64, 3), num_classes=6)

history = History()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)

model_RESNETmelspec.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
model_RESNETmelspec.summary()

"""## MELSPEC"""

history_melspec = model_RESNETmelspec.fit(training_set, validation_data = test_set, batch_size=64,epochs=15,callbacks=[history])

plt.figure(figsize=(14,8))
plt.plot(history_melspec.history['accuracy'])
plt.plot(history_melspec.history['val_accuracy'])
plt.title('Model Accuracy', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

 # summarize history for loss
plt.figure(figsize=(14,8))
plt.plot(history_melspec.history['loss'])
plt.plot(history_melspec.history['val_loss'])
plt.title('Model Loss', fontsize=14)
plt.ylabel('Loss',fontsize=12)
plt.xlabel('Epoch',fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

accuracy = model_RESNETmelspec.evaluate(test_set)
print('n', 'Test_Accuracy:-', accuracy[1])
pred = model_RESNETmelspec.predict(test_set)
y_pred = np.argmax(pred, axis=1)

#y_true = np.argmax(pred, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set.classes, y_pred))

    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set.classes, y_pred), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred")
plt.ylabel("y_true")
plt.show()

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set1 = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/melspec_split/test',
                                            target_size = (64, 64),
                                            shuffle=False)#berbeda dengan test_set diatas, diatas menggunakan validasi sedangkan ini menggunakan data dari folder test

accuracy = model_RESNETmelspec.evaluate(test_set1)
print('n', 'Test_Accuracy:-', accuracy[1])
pred1 = model_RESNETmelspec.predict(test_set1)
y_pred1 = np.argmax(pred1, axis=1)
#y_true = np.argmax(pred1, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set1.classes, y_pred1))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set1.classes, y_pred1), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred1")
plt.ylabel("y_true")
plt.show()

"""Save model MELSPEC_RESNET"""

import torch

# Assuming you have a model instance called 'model'
# and that you've trained it already

# Define the path where you want to save the model in Kaggle
model_save_path_melspec = '/kaggle/working/'

# Save the model's state_dict
torch.save(model.state_dict(), model_save_path_melspec)

print(f'Model saved to {model_save_path_melspec}')

"""## MFCC_RESNET"""

training_set_mfcc = train_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/train',
                                                 target_size = (64, 64),
                                                 shuffle=True)

test_set_mfcc = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/val',
                                            target_size = (64, 64),
                                            shuffle=False)

import tensorflow as tf
from keras.callbacks import History

# Function to create a residual block with shortcut adjustment
def residual_block(x, filters, use_shortcut=True):
    shortcut = x
    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(x)
    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)

    if use_shortcut:
        # Adjust shortcut if the number of filters has changed
        if x.shape[-1] != shortcut.shape[-1]:
            shortcut = tf.keras.layers.Conv2D(filters, (1, 1), padding='same')(shortcut)

    x = tf.keras.layers.add([x, shortcut])  # Add shortcut connection
    x = tf.keras.layers.Activation('relu')(x)
    return x

# Build ResNet model
def build_resnet(input_shape, num_classes):
    inputs = tf.keras.Input(shape=input_shape)
    x = tf.keras.layers.Conv2D(64, (7, 7), padding='same', activation='relu')(inputs)
    x = tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)

    # Add residual blocks
    for _ in range(2):  # Repeat 2 times for each block
        x = residual_block(x, 64)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 128)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 256)

    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(x)

    for _ in range(2):
        x = residual_block(x, 512)

    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    x = tf.keras.layers.Dense(512, activation='relu')(x)
    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)

    model = tf.keras.Model(inputs, outputs)
    return model

# Instantiate and compile the model
model_mfccRESNET = build_resnet(input_shape=(64, 64, 3), num_classes=6)

history = History()
optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)

model_mfccRESNET.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])
model_mfccRESNET.summary()

History_mfcc = model_mfccRESNET.fit(training_set_mfcc, validation_data = test_set_mfcc, batch_size=32,epochs=25,callbacks=[history])

plt.figure(figsize=(14,8))
plt.plot(History_mfcc.history['accuracy'])
plt.plot(History_mfcc.history['val_accuracy'])
plt.title('Model Accuracy', fontsize=14)
plt.ylabel('Accuracy', fontsize=12)
plt.xlabel('Epoch', fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

 # summarize history for loss
plt.figure(figsize=(14,8))
plt.plot(History_mfcc.history['loss'])
plt.plot(History_mfcc.history['val_loss'])
plt.title('Model Loss', fontsize=14)
plt.ylabel('Loss',fontsize=12)
plt.xlabel('Epoch',fontsize=12)
plt.legend(['train', 'test'], loc='upper left')
plt.show()

accuracy = model_mfccRESNET.evaluate(test_set_mfcc)
print('n', 'Test_Accuracy:-', accuracy[1])
pred2 = model_mfccRESNET.predict(test_set_mfcc)
y_pred_mfcc = np.argmax(pred2, axis=1)
#y_true = np.argmax(pred2, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set_mfcc.classes, y_pred_mfcc))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set_mfcc.classes, y_pred_mfcc), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred_mfcc")
plt.ylabel("y_true")
plt.show()

test_datagen = ImageDataGenerator(rescale = 1./255)
test_set2 = test_datagen.flow_from_directory('/kaggle/input/dl-20242025-itera-west-indonesia-birds-dataset/split_data/mfcc_split/test',
                                            target_size = (64, 64),
                                            shuffle=False)#berbeda dengan test_set diatas, diatas menggunakan validasi sedangkan ini menggunakan data dari folder test

accuracy = model_mfccRESNET.evaluate(test_set2)
print('n', 'Test_Accuracy:-', accuracy[1])
pred1 = model_mfccRESNET.predict(test_set2)
y_pred_mfccRESNET = np.argmax(pred1, axis=1)
#y_true = np.argmax(pred1, axis=1)
print('confusion matrix')
print(confusion_matrix(test_set2.classes, y_pred_mfccRESNET))
    #confusion matrix
f, ax = plt.subplots(figsize=(14,8))
sns.heatmap(confusion_matrix(test_set2.classes, y_pred_mfccRESNET), annot=True, fmt=".0f", ax=ax)
plt.xlabel("y_pred_mfccRESNET")
plt.ylabel("y_true")
plt.show()

"""Save MFCC RESNET MODEL"""

# Save the model
model_save_path = '/kaggle/working/model_mfccRESNET1.h5'  # Change this path as needed
model_mfccRESNET.save(model_save_path)

print(f'Model saved to {model_save_path}')

# Commented out IPython magic to ensure Python compatibility.
# %cd /kaggle/working
from IPython.display import FileLink
FileLink('/kaggle/working/model_mfccRESNET1.h5')

from IPython.display import FileLink
FileLink(r'/kaggle/working/model_mfccRESNET1.h5')

"""# Coba dengan data suara lain"""

import tensorflow as tf
import numpy as np
import librosa

# Load the model
model_save_path = '/kaggle/working/model_mfccRESNET1.h5'  # Path where the model is saved
loaded_model = tf.keras.models.load_model(model_save_path)

# Function to extract MFCC features from an audio file
def extract_mfcc(file_path, sr=22050, n_mfcc=64, n_fft=2048, hop_length=512):
    # Load the audio file
    y, _ = librosa.load(file_path, sr=sr)

    # Extract MFCC features
    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)

    # Transpose to get shape (n_mfcc, time)
    mfccs = mfccs.T  # Shape: (time, n_mfcc)

    # Ensure the shape is (64, n_mfcc) for model input
    if mfccs.shape[0] < 64:
        mfccs = np.pad(mfccs, ((0, 64 - mfccs.shape[0]), (0, 0)), mode='constant')
    else:
        mfccs = mfccs[:64, :]

    # Duplicate the single-channel MFCCs to create a 3-channel input
    mfccs = np.stack([mfccs] * 3, axis=-1)  # Shape: (64, 64, 3)

    return mfccs

# Function to classify an audio file
def classify_audio(file_path):
    # Extract features
    features = extract_mfcc(file_path)

    # Add batch dimension
    features = np.expand_dims(features, axis=0)  # Shape: (1, 64, 64, 3)

    # Make predictions
    predictions = loaded_model.predict(features)

    # Get the predicted class
    predicted_class = np.argmax(predictions, axis=1)

    return predicted_class

# Example usage
audio_file_path = '/kaggle/input/anthipes-solitaris/XC490588 - Sikatan kerongkongan-putih - Anthipes solitaris.mp3'
#data yang digunakan memiliki kelas aktual 5
predicted_class = classify_audio(audio_file_path)

print(f'Predicted class: {predicted_class[0]}')